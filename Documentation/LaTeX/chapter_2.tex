% Filename: main.tex
% Description: Review of Related Literature

\chapter{Review of Related Literature}

This chapter discusses... Hey guys, we need to put some filler text here to be honest. Right now its just random stuff but soon enough we should have something that we can place right here.

\section{Automatic Speech technology}

Automatic speech recognition (ASR) by machine has been a field of research for more than five decades. The industry has developed a broad range of commercial products where ASR as user interface has become ever more useful and pervasive [a1]. Automatic Speech Technologies are used daily in several applications and services. However, ASR technology has not reached a point where computers understand all speech in any acoustic environment or by any person. [a2]

The basic architecture of ASR involves four main components: signal processing and feature extraction, acoustic model (AM), language model (LM), and hypothesis search. Audio signals which are taken as input for signal processing and feature extraction components are enhanced and converted so it becomes suitable for acoustic models. The acoustic models are responsible for integrating knowledge about acoustics and phonetics. The language model processes the probability of a hypothesized word sequence from what it has learned from training. The hypothesis search component will combine the previous scores from both AM and LM and outputs a word sequence. [a3]

\section{Speech Recognition Toolkits}

Over the last few decades, commercial proprietary speech recognition systems have emerged such as AT&T Watson [b1], Microsoft Speech Server [b2], Google Speech API [b3] and Nuance Recognizer [b4]. These systems, however, are difficult to integrate into other software and they offered no control over the recognizerâ€™s features which led to the development of open-source automatic speech recognition systems.  

In 2014, a comparative study was performed that involved training language and acoustic models for open-source ASR toolkits such as HDecode, Julius, pocketsphinx, Sphinx-4, and Kaldi. Their experiments showed an order of the evaluated toolkits regarding the ratio of effort to performance. The results showed that Kaldi outperformed all the other recognition toolkits when provided given out of the box training and decoding pipelines. The Sphinx also showed that it could provide training pipelines with a high possibility of achieving good results in a short amount of time.  [b5]

%Aklanon language usage here

\section{Etymology of the Aklanon Language}

While it is almost impossible to track the actual stages of development of the language, in a book published by De La Cruz and Zorc on Aklanon Grammar (De La Cruz & Zorc, 1968), the language comes from a long history of evolution of proto-languages which now turned out to be the present day Aklanon. The language itself has freely adopted English words. These words were simplified and have taken their own form of spellings. Aside from English words, there are also words borrowed from China, Spain and Japan that have been derived from to form Aklanon words. (Zorc, Prado, \& Reyes, 1969)

\section{Glottal Stop}

The glottal stop presents a potential issue with speech to text recognition as native speakers of the Aklanon language, like most of its neighboring dialects, generally have a system wherein the words do not actually sound like they are spelled. These glottal stops have different rules concerning their positions such as initially before a vowel, medially between vowels, consonants or when a double glottal appears, and lastly the glottal at the final position (Zorc, Prado, \& Reyes, 1969). Depending on how an individual might pronounce certain words, the results from speech to text recognition could possibly vary as different stress intonations on several words could result in a mismatch in recognition.